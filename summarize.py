"""
summarize.py â€” AI-powered chat summarization using Claude

Takes OCR-extracted chat text and generates a structured Markdown summary.
"""

import os
import re
from pathlib import Path
from datetime import datetime

def create_summary_prompt(chat_text: str) -> str:
    """Create the summarization prompt for Claude."""
    return f"""ä½ æ˜¯ä¸€ä¸ªå¾®ä¿¡ç¾¤èŠæ€»ç»“åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯ä»å¾®ä¿¡ç¾¤èŠæˆªå›¾ä¸­é€šè¿‡ OCR æå–çš„èŠå¤©è®°å½•ã€‚
è¯·å¯¹è¿™äº›èŠå¤©å†…å®¹è¿›è¡Œç»“æ„åŒ–æ•´ç†å’Œæ€»ç»“ã€‚

## è¦æ±‚

1. **è®¨è®ºçºªè¦**ï¼ˆè¯¦ç»†æ•´ç†ï¼‰ï¼š
   - æŒ‰æ—¶é—´é¡ºåºå’Œè¯é¢˜ï¼Œ**å®Œæ•´åœ°**æ•´ç†èŠå¤©å†…å®¹
   - å°†å£è¯­åŒ–çš„è¡¨è¾¾æ”¹å†™ä¸ºæ›´é€šé¡ºã€æ˜“è¯»çš„ä¹¦é¢è¯­
   - ä¿ç•™æ‰€æœ‰æœ‰æ„ä¹‰çš„å‘è¨€ï¼Œæ ‡æ³¨å‘è¨€äºº
   - ä¸è¦è¿‡åº¦ç²¾ç®€ï¼Œä¿æŒä¸åŸæ–‡æ¥è¿‘çš„ä¿¡æ¯é‡
   - ä¿®æ­£ OCR è¯†åˆ«é”™è¯¯ã€è¡¥å……è¢«æˆªæ–­çš„å†…å®¹
   - åˆå¹¶åŒä¸€äººçš„è¿ç»­å‘è¨€ï¼Œä½†ä¸è¦åˆå¹¶ä¸åŒè¯é¢˜

2. **æ¦‚è¦**ï¼šä¸€æ®µè¯æ¦‚æ‹¬ä¸»è¦è®¨è®ºå†…å®¹

3. **è¯é¢˜è®¨è®º**ï¼šæŒ‰ä¸»é¢˜å½’ç±»ï¼Œæç‚¼æ ¸å¿ƒè§‚ç‚¹

4. **æå–å…³é”®ä¿¡æ¯**ï¼š
   - é‡è¦å†³å®šæˆ–ç»“è®º
   - åˆ†äº«çš„é“¾æ¥æˆ–èµ„æº
   - Action items / å¾…åŠäº‹é¡¹
   - æœ‰ä»·å€¼çš„è§‚ç‚¹æˆ–å»ºè®®

5. **ä¸­æ–‡è¾“å‡º**ï¼šä½¿ç”¨ä¸­æ–‡æ’°å†™

## è¾“å‡ºæ ¼å¼

ä½¿ç”¨ Markdown æ ¼å¼ï¼Œç»“æ„å¦‚ä¸‹ï¼š

# ç¾¤èŠæ€»ç»“ â€” [æ—¥æœŸ]

## ğŸ“ è®¨è®ºçºªè¦
ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ•´ç†çš„å®Œæ•´è®¨è®ºå†…å®¹ï¼Œå£è¯­è½¬ä¹¦é¢è¯­ï¼Œä¿ç•™ç»†èŠ‚å’Œå‘è¨€äººã€‚
  æŒ‰è¯é¢˜ç”¨ä¸‰çº§æ ‡é¢˜åˆ†éš”ï¼Œæ¯ä¸ªå‘è¨€äººçš„å†…å®¹ç”¨åˆ—è¡¨å‘ˆç°ã€‚ï¼‰

## ğŸ“‹ æ¦‚è¦
ï¼ˆä¸€æ®µè¯æ¦‚æ‹¬ä»Šå¤©çš„ä¸»è¦è®¨è®ºå†…å®¹ï¼‰

## ğŸ’¬ è¯é¢˜è®¨è®º

### è¯é¢˜ 1: [è¯é¢˜åç§°]
- **[å‘è¨€äººA]**: è§‚ç‚¹/å†…å®¹
- **[å‘è¨€äººB]**: è§‚ç‚¹/å†…å®¹
- ...

### è¯é¢˜ 2: [è¯é¢˜åç§°]
...

## âœ… Action Items
- [ ] å¾…åŠäº‹é¡¹ 1 (è´Ÿè´£äºº: xxx)
- [ ] å¾…åŠäº‹é¡¹ 2

## ğŸ”— åˆ†äº«çš„èµ„æº
- [èµ„æºæè¿°](é“¾æ¥)

---

## èŠå¤©è®°å½•

```
{chat_text}
```"""


def create_chunk_summary_prompt(chat_text: str, chunk_index: int, total_chunks: int) -> str:
    """Create prompt for a single chunk summary."""
    return f"""ä½ æ˜¯ä¸€ä¸ªå¾®ä¿¡ç¾¤èŠæ€»ç»“åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯ç¬¬ {chunk_index}/{total_chunks} ä¸ªèŠå¤©è®°å½•åˆ†å—ã€‚

è¯·è¾“å‡ºè¯¥åˆ†å—çš„ç»“æ„åŒ–æ‘˜è¦ï¼Œé‡ç‚¹ä¿ç•™äº‹å®ã€ç»“è®ºã€åˆ†æ­§ã€è¡ŒåŠ¨é¡¹ã€èµ„æºé“¾æ¥ã€‚
ä¸è¦è‡†æµ‹ï¼Œä¸è¦è¡¥å……èŠå¤©ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯ã€‚

## è¾“å‡ºæ ¼å¼ï¼ˆMarkdownï¼‰

### Chunk {chunk_index} æ¦‚è¦
- 2-4 å¥ï¼Œè¯´æ˜è¯¥åˆ†å—ä¸»è¦è®¨è®ºäº†ä»€ä¹ˆ

### Chunk {chunk_index} å…³é”®è®¨è®ºç‚¹
- æŒ‰ä¸»é¢˜åˆ—å‡ºæ ¸å¿ƒè§‚ç‚¹ï¼Œå°½é‡æ ‡æ³¨å‘è¨€äºº

### Chunk {chunk_index} ç»“è®ºä¸å†³å®š
- è‹¥æ²¡æœ‰ï¼Œå†™â€œæ— æ˜ç¡®ç»“è®ºâ€

### Chunk {chunk_index} Action Items
- [ ] äº‹é¡¹ (è´Ÿè´£äºº: xxx / æœªæ˜ç¡®)

### Chunk {chunk_index} èµ„æºä¸é“¾æ¥
- èµ„æºåç§°: é“¾æ¥ï¼ˆå¦‚æœ‰ï¼‰

---

## åˆ†å—èŠå¤©è®°å½•

```
{chat_text}
```"""


def create_merge_summary_prompt(chunk_summaries: list[str]) -> str:
    """Create prompt to merge chunk summaries into one final summary."""
    joined = "\n\n".join(
        f"## åˆ†å—æ‘˜è¦ {index}\n{summary}"
        for index, summary in enumerate(chunk_summaries, start=1)
    )
    return f"""ä½ æ˜¯ä¸€ä¸ªå¾®ä¿¡ç¾¤èŠæ€»ç»“åŠ©æ‰‹ã€‚ä¸‹é¢æ˜¯å¤šä¸ªåˆ†å—æ‘˜è¦ï¼Œè¯·åˆå¹¶æˆæœ€ç»ˆæ€»ç»“ã€‚

è¦æ±‚ï¼š
1. åˆå¹¶é‡å¤ä¿¡æ¯ï¼Œä¿ç•™æ—¶é—´è„‰ç»œå’Œè¯é¢˜ç»“æ„
2. å†²çªè§‚ç‚¹è¦å¹¶åˆ—å‘ˆç°ï¼Œä¸è¦æ“…è‡ªè£å†³
3. Action Items å»é‡å¹¶å°½é‡è¡¥å…¨è´Ÿè´£äºº
4. é“¾æ¥ä¸èµ„æºå»é‡åæŒ‰ä¸»é¢˜å½’ç±»
5. è¾“å‡ºä¸­æ–‡ï¼Œä½¿ç”¨ Markdown

æœ€ç»ˆè¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ï¼š

# ç¾¤èŠæ€»ç»“ â€” [æ—¥æœŸ]

## ğŸ“ è®¨è®ºçºªè¦
ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ•´ç†ï¼ŒæŒ‰è¯é¢˜åˆ†æ®µï¼Œä¿ç•™å…³é”®ç»†èŠ‚å’Œå‘è¨€äººï¼‰

## ğŸ“‹ æ¦‚è¦
ï¼ˆä¸€æ®µè¯æ¦‚æ‹¬ï¼‰

## ğŸ’¬ è¯é¢˜è®¨è®º
### è¯é¢˜ 1: [è¯é¢˜åç§°]
- **[å‘è¨€äºº]**: è§‚ç‚¹

## âœ… Action Items
- [ ] äº‹é¡¹ (è´Ÿè´£äºº: xxx)

## ğŸ”— åˆ†äº«çš„èµ„æº
- [èµ„æºæè¿°](é“¾æ¥)

---

## åˆ†å—æ‘˜è¦è¾“å…¥

{joined}
"""


def summarize_chat(
    chat_text: str,
    model: str = "claude-sonnet-4-20250514",
    max_tokens: int = 8192,
) -> str:
    """
    Generate a structured summary of the chat text using Claude.

    Args:
        chat_text: OCR-extracted chat text
        model: Claude model to use
        max_tokens: Maximum tokens for the response

    Returns:
        Markdown-formatted summary
    """
    client = _build_anthropic_client()
    prompt = create_summary_prompt(chat_text)
    return _send_prompt(client, prompt, model, max_tokens, label="full summary")


def summarize_chat_in_chunks(
    chat_chunks: list[str],
    model: str = "claude-sonnet-4-20250514",
    max_tokens: int = 8192,
    chunk_max_tokens: int = 4096,
) -> str:
    """Summarize chunk texts first, then merge into one final summary."""
    usable_chunks = [chunk for chunk in chat_chunks if chunk and chunk.strip()]
    if not usable_chunks:
        raise ValueError("No non-empty chat chunks provided.")
    if len(usable_chunks) == 1:
        return summarize_chat(usable_chunks[0], model=model, max_tokens=max_tokens)

    client = _build_anthropic_client()
    chunk_summaries = []

    for index, chunk_text in enumerate(usable_chunks, start=1):
        prompt = create_chunk_summary_prompt(chunk_text, index, len(usable_chunks))
        chunk_summary = _send_prompt(
            client,
            prompt,
            model,
            chunk_max_tokens,
            label=f"chunk {index}/{len(usable_chunks)}",
        )
        chunk_summaries.append(chunk_summary)

    merge_prompt = create_merge_summary_prompt(chunk_summaries)
    return _send_prompt(client, merge_prompt, model, max_tokens, label="final merge")


def _load_local_env() -> None:
    """Load .env.local when python-dotenv is available."""
    try:
        from dotenv import load_dotenv
    except Exception:  # noqa: BLE001
        return
    load_dotenv(".env.local", override=False)


def _build_anthropic_client():
    """Create Anthropic client after loading environment."""
    _load_local_env()
    try:
        import anthropic
    except ImportError as exc:
        raise RuntimeError(
            "Anthropic SDK is not installed. Install dependencies from requirements.txt."
        ) from exc

    api_key = os.environ.get("ANTHROPIC_AUTH_TOKEN") or os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        raise ValueError(
            "ANTHROPIC_AUTH_TOKEN or ANTHROPIC_API_KEY environment variable is required. "
            "Set it in .env.local or your environment."
        )

    base_url = os.environ.get("ANTHROPIC_BASE_URL")
    return anthropic.Anthropic(api_key=api_key, **(dict(base_url=base_url) if base_url else {}))


def _send_prompt(client, prompt: str, model: str, max_tokens: int, label: str) -> str:
    """Send prompt to Claude and return concatenated text blocks."""
    print(f"Sending {len(prompt)} chars to Claude ({model}) for {label}...")

    message = client.messages.create(
        model=model,
        max_tokens=max_tokens,
        messages=[{"role": "user", "content": prompt}],
    )

    text_blocks = [block.text for block in message.content if hasattr(block, "text")]
    summary = "\n".join(text_blocks).strip()
    if not summary:
        raise RuntimeError(f"Claude returned empty response for {label}.")

    print(f"{label} generated: {len(summary)} chars")
    print(f"Tokens used: input={message.usage.input_tokens}, output={message.usage.output_tokens}")
    return summary


def save_summary(
    summary: str,
    output_dir: str = "output",
    group_name: str = "ç¾¤èŠ",
) -> str:
    """
    Save the summary as a Markdown file.

    Args:
        summary: The generated summary text
        output_dir: Output directory
        group_name: Name of the chat group

    Returns:
        Path to the saved file
    """
    out = Path(output_dir)
    out.mkdir(parents=True, exist_ok=True)

    safe_group = _sanitize_filename_component(group_name)
    date_str = datetime.now().strftime("%Y-%m-%d")
    filename = f"{date_str}_{safe_group}.md"
    filepath = out / filename

    filepath.write_text(summary, encoding="utf-8")
    if safe_group != group_name:
        print(f"Group name sanitized for filename: {safe_group}")
    print(f"Summary saved to {filepath}")
    return str(filepath)


def _sanitize_filename_component(value: str) -> str:
    """Sanitize user input for safe cross-platform filenames."""
    cleaned = re.sub(r'[<>:"/\\|?*\x00-\x1f]', "_", value).strip().strip(".")
    cleaned = re.sub(r"\s+", " ", cleaned)
    cleaned = cleaned[:80]
    return cleaned or "group"


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Summarize WeChat chat text")
    parser.add_argument("--input", required=True, help="Input text file")
    parser.add_argument("--output-dir", default="output", help="Output directory")
    parser.add_argument("--group", default="ç¾¤èŠ", help="Group chat name")
    parser.add_argument("--model", default="claude-sonnet-4-20250514", help="Claude model")
    args = parser.parse_args()

    text = Path(args.input).read_text(encoding="utf-8")
    summary = summarize_chat(text, model=args.model)
    save_summary(summary, output_dir=args.output_dir, group_name=args.group)
